#!/usr/bin/env python3
"""
HuggingFace MCP Server - è‡ªå®šä¹‰å®ç°

æä¾› HuggingFace Hub çš„æ¨¡å‹ã€æ•°æ®é›†å’Œç©ºé—´è®¿é—®èƒ½åŠ›ã€‚
ä½¿ç”¨ FastMCP æ¡†æ¶å’Œ HuggingFace Hub APIã€‚
"""

import os
import sys
from typing import Optional, Dict, List, Any

try:
    from mcp.server.fastmcp import FastMCP
    from huggingface_hub import HfApi, hf_hub_download, list_models, list_datasets
    from huggingface_hub.utils import HfHubHTTPError
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}", file=sys.stderr)
    print("è¯·è¿è¡Œ: pip install mcp huggingface-hub", file=sys.stderr)
    sys.exit(1)

# åˆ›å»º MCP æœåŠ¡å™¨å®ä¾‹
mcp = FastMCP("huggingface")

# åˆå§‹åŒ– HuggingFace API å®¢æˆ·ç«¯
token = os.getenv("HUGGINGFACE_TOKEN")
if not token:
    print("âš ï¸  è­¦å‘Š: HUGGINGFACE_TOKEN æœªè®¾ç½®,æŸäº›åŠŸèƒ½å¯èƒ½å—é™", file=sys.stderr)

api = HfApi(token=token)


@mcp.tool()
def search_models(
    query: str,
    limit: int = 10,
    sort: str = "downloads",
    direction: int = -1
) -> List[Dict[str, Any]]:
    """
    æœç´¢ HuggingFace æ¨¡å‹
    
    Args:
        query: æœç´¢å…³é”®è¯
        limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶ (é»˜è®¤: 10)
        sort: æ’åºå­—æ®µ (downloads/likes/trending/created_at)
        direction: æ’åºæ–¹å‘ (-1=é™åº, 1=å‡åº)
    
    Returns:
        æ¨¡å‹åˆ—è¡¨,åŒ…å« idã€ä½œè€…ã€ä¸‹è½½é‡ã€ç‚¹èµæ•°ç­‰ä¿¡æ¯
    """
    try:
        models = list(api.list_models(
            search=query,
            limit=limit,
            sort=sort,
            direction=direction
        ))
        
        return [{
            "id": model.id,
            "author": model.author if hasattr(model, 'author') else None,
            "downloads": model.downloads if hasattr(model, 'downloads') else 0,
            "likes": model.likes if hasattr(model, 'likes') else 0,
            "tags": model.tags if hasattr(model, 'tags') else [],
            "pipeline_tag": model.pipeline_tag if hasattr(model, 'pipeline_tag') else None,
            "created_at": str(model.created_at) if hasattr(model, 'created_at') else None,
        } for model in models]
    except Exception as e:
        return {"error": f"æœç´¢æ¨¡å‹å¤±è´¥: {str(e)}"}


@mcp.tool()
def get_model_info(model_id: str) -> Dict[str, Any]:
    """
    è·å–æ¨¡å‹è¯¦ç»†ä¿¡æ¯
    
    Args:
        model_id: æ¨¡å‹ID (ä¾‹å¦‚: bert-base-uncased, gpt2)
    
    Returns:
        æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯,åŒ…æ‹¬å…ƒæ•°æ®ã€æ–‡ä»¶åˆ—è¡¨ã€æ ‡ç­¾ç­‰
    """
    try:
        info = api.model_info(model_id)
        
        return {
            "id": info.id,
            "author": info.author if hasattr(info, 'author') else None,
            "sha": info.sha if hasattr(info, 'sha') else None,
            "downloads": info.downloads if hasattr(info, 'downloads') else 0,
            "likes": info.likes if hasattr(info, 'likes') else 0,
            "tags": info.tags if hasattr(info, 'tags') else [],
            "pipeline_tag": info.pipeline_tag if hasattr(info, 'pipeline_tag') else None,
            "library_name": info.library_name if hasattr(info, 'library_name') else None,
            "created_at": str(info.created_at) if hasattr(info, 'created_at') else None,
            "last_modified": str(info.last_modified) if hasattr(info, 'last_modified') else None,
            "card_data": info.card_data.to_dict() if hasattr(info, 'card_data') and info.card_data else {},
            "siblings": [{"rfilename": f.rfilename, "size": f.size} for f in info.siblings] if hasattr(info, 'siblings') else []
        }
    except HfHubHTTPError as e:
        return {"error": f"æ¨¡å‹ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {str(e)}"}
    except Exception as e:
        return {"error": f"è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {str(e)}"}


@mcp.tool()
def search_datasets(
    query: str,
    limit: int = 10,
    sort: str = "downloads",
    direction: int = -1
) -> List[Dict[str, Any]]:
    """
    æœç´¢ HuggingFace æ•°æ®é›†
    
    Args:
        query: æœç´¢å…³é”®è¯
        limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶ (é»˜è®¤: 10)
        sort: æ’åºå­—æ®µ (downloads/likes/trending/created_at)
        direction: æ’åºæ–¹å‘ (-1=é™åº, 1=å‡åº)
    
    Returns:
        æ•°æ®é›†åˆ—è¡¨,åŒ…å« idã€ä½œè€…ã€ä¸‹è½½é‡ã€ç‚¹èµæ•°ç­‰ä¿¡æ¯
    """
    try:
        datasets = list(api.list_datasets(
            search=query,
            limit=limit,
            sort=sort,
            direction=direction
        ))
        
        return [{
            "id": dataset.id,
            "author": dataset.author if hasattr(dataset, 'author') else None,
            "downloads": dataset.downloads if hasattr(dataset, 'downloads') else 0,
            "likes": dataset.likes if hasattr(dataset, 'likes') else 0,
            "tags": dataset.tags if hasattr(dataset, 'tags') else [],
            "created_at": str(dataset.created_at) if hasattr(dataset, 'created_at') else None,
        } for dataset in datasets]
    except Exception as e:
        return {"error": f"æœç´¢æ•°æ®é›†å¤±è´¥: {str(e)}"}


@mcp.tool()
def get_dataset_info(dataset_id: str) -> Dict[str, Any]:
    """
    è·å–æ•°æ®é›†è¯¦ç»†ä¿¡æ¯
    
    Args:
        dataset_id: æ•°æ®é›†ID (ä¾‹å¦‚: squad, imdb)
    
    Returns:
        æ•°æ®é›†çš„è¯¦ç»†ä¿¡æ¯,åŒ…æ‹¬å…ƒæ•°æ®ã€æ–‡ä»¶åˆ—è¡¨ã€æ ‡ç­¾ç­‰
    """
    try:
        info = api.dataset_info(dataset_id)
        
        return {
            "id": info.id,
            "author": info.author if hasattr(info, 'author') else None,
            "sha": info.sha if hasattr(info, 'sha') else None,
            "downloads": info.downloads if hasattr(info, 'downloads') else 0,
            "likes": info.likes if hasattr(info, 'likes') else 0,
            "tags": info.tags if hasattr(info, 'tags') else [],
            "created_at": str(info.created_at) if hasattr(info, 'created_at') else None,
            "last_modified": str(info.last_modified) if hasattr(info, 'last_modified') else None,
            "card_data": info.card_data.to_dict() if hasattr(info, 'card_data') and info.card_data else {},
            "siblings": [{"rfilename": f.rfilename, "size": f.size} for f in info.siblings] if hasattr(info, 'siblings') else []
        }
    except HfHubHTTPError as e:
        return {"error": f"æ•°æ®é›†ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {str(e)}"}
    except Exception as e:
        return {"error": f"è·å–æ•°æ®é›†ä¿¡æ¯å¤±è´¥: {str(e)}"}


@mcp.tool()
def list_model_files(model_id: str) -> List[Dict[str, Any]]:
    """
    åˆ—å‡ºæ¨¡å‹ä»“åº“ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    
    Args:
        model_id: æ¨¡å‹ID
    
    Returns:
        æ–‡ä»¶åˆ—è¡¨,åŒ…å«æ–‡ä»¶åå’Œå¤§å°
    """
    try:
        info = api.model_info(model_id)
        files = []
        
        if hasattr(info, 'siblings'):
            files = [{
                "filename": f.rfilename,
                "size": f.size,
                "size_mb": round(f.size / (1024 * 1024), 2) if f.size else 0
            } for f in info.siblings]
        
        return files
    except Exception as e:
        return {"error": f"åˆ—å‡ºæ¨¡å‹æ–‡ä»¶å¤±è´¥: {str(e)}"}


@mcp.tool()
def list_dataset_files(dataset_id: str) -> List[Dict[str, Any]]:
    """
    åˆ—å‡ºæ•°æ®é›†ä»“åº“ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    
    Args:
        dataset_id: æ•°æ®é›†ID
    
    Returns:
        æ–‡ä»¶åˆ—è¡¨,åŒ…å«æ–‡ä»¶åå’Œå¤§å°
    """
    try:
        info = api.dataset_info(dataset_id)
        files = []
        
        if hasattr(info, 'siblings'):
            files = [{
                "filename": f.rfilename,
                "size": f.size,
                "size_mb": round(f.size / (1024 * 1024), 2) if f.size else 0
            } for f in info.siblings]
        
        return files
    except Exception as e:
        return {"error": f"åˆ—å‡ºæ•°æ®é›†æ–‡ä»¶å¤±è´¥: {str(e)}"}


@mcp.tool()
def download_model_file(
    model_id: str,
    filename: str,
    local_dir: Optional[str] = None
) -> Dict[str, str]:
    """
    ä¸‹è½½æ¨¡å‹æ–‡ä»¶
    
    Args:
        model_id: æ¨¡å‹ID
        filename: è¦ä¸‹è½½çš„æ–‡ä»¶å
        local_dir: æœ¬åœ°ä¿å­˜ç›®å½• (å¯é€‰)
    
    Returns:
        ä¸‹è½½æ–‡ä»¶çš„æœ¬åœ°è·¯å¾„å’Œç›¸å…³ä¿¡æ¯
    """
    if not token:
        return {"error": "éœ€è¦ HUGGINGFACE_TOKEN æ‰èƒ½ä¸‹è½½æ–‡ä»¶"}
    
    try:
        path = hf_hub_download(
            repo_id=model_id,
            filename=filename,
            repo_type="model",
            local_dir=local_dir,
            token=token
        )
        
        return {
            "success": True,
            "path": path,
            "model_id": model_id,
            "filename": filename
        }
    except Exception as e:
        return {"error": f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {str(e)}"}


@mcp.tool()
def download_dataset_file(
    dataset_id: str,
    filename: str,
    local_dir: Optional[str] = None
) -> Dict[str, str]:
    """
    ä¸‹è½½æ•°æ®é›†æ–‡ä»¶
    
    Args:
        dataset_id: æ•°æ®é›†ID
        filename: è¦ä¸‹è½½çš„æ–‡ä»¶å
        local_dir: æœ¬åœ°ä¿å­˜ç›®å½• (å¯é€‰)
    
    Returns:
        ä¸‹è½½æ–‡ä»¶çš„æœ¬åœ°è·¯å¾„å’Œç›¸å…³ä¿¡æ¯
    """
    if not token:
        return {"error": "éœ€è¦ HUGGINGFACE_TOKEN æ‰èƒ½ä¸‹è½½æ–‡ä»¶"}
    
    try:
        path = hf_hub_download(
            repo_id=dataset_id,
            filename=filename,
            repo_type="dataset",
            local_dir=local_dir,
            token=token
        )
        
        return {
            "success": True,
            "path": path,
            "dataset_id": dataset_id,
            "filename": filename
        }
    except Exception as e:
        return {"error": f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {str(e)}"}


@mcp.tool()
def get_user_info(username: str) -> Dict[str, Any]:
    """
    è·å–ç”¨æˆ·ä¿¡æ¯
    
    Args:
        username: HuggingFace ç”¨æˆ·å
    
    Returns:
        ç”¨æˆ·çš„è¯¦ç»†ä¿¡æ¯
    """
    try:
        info = api.whoami(token=token) if username == "me" and token else None
        
        if info:
            return {
                "name": info.get("name"),
                "fullname": info.get("fullname"),
                "email": info.get("email"),
                "orgs": [org.get("name") for org in info.get("orgs", [])],
                "auth": info.get("auth", {})
            }
        else:
            # å¯¹äºå…¶ä»–ç”¨æˆ·,è¿”å›åŸºæœ¬ä¿¡æ¯
            return {"error": "éœ€è¦è®¤è¯æ‰èƒ½æŸ¥çœ‹ç”¨æˆ·ä¿¡æ¯,æˆ–ä½¿ç”¨ 'me' æŸ¥çœ‹å½“å‰ç”¨æˆ·"}
    except Exception as e:
        return {"error": f"è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {str(e)}"}


def main():
    """ä¸»å‡½æ•° - è¿è¡Œ MCP æœåŠ¡å™¨"""
    print("ğŸš€ å¯åŠ¨ HuggingFace MCP æœåŠ¡å™¨...", file=sys.stderr)
    
    if token:
        print(f"âœ… ä½¿ç”¨ HuggingFace Token: {token[:10]}...", file=sys.stderr)
    else:
        print("âš ï¸  æœªè®¾ç½® HUGGINGFACE_TOKEN,æŸäº›åŠŸèƒ½å°†å—é™", file=sys.stderr)
    
    print("ğŸ“¡ æœåŠ¡å™¨è¿è¡Œåœ¨ STDIO æ¨¡å¼", file=sys.stderr)
    print("ğŸ”§ æä¾› 10 ä¸ªå·¥å…·:", file=sys.stderr)
    print("   - search_models: æœç´¢æ¨¡å‹", file=sys.stderr)
    print("   - get_model_info: è·å–æ¨¡å‹ä¿¡æ¯", file=sys.stderr)
    print("   - search_datasets: æœç´¢æ•°æ®é›†", file=sys.stderr)
    print("   - get_dataset_info: è·å–æ•°æ®é›†ä¿¡æ¯", file=sys.stderr)
    print("   - list_model_files: åˆ—å‡ºæ¨¡å‹æ–‡ä»¶", file=sys.stderr)
    print("   - list_dataset_files: åˆ—å‡ºæ•°æ®é›†æ–‡ä»¶", file=sys.stderr)
    print("   - download_model_file: ä¸‹è½½æ¨¡å‹æ–‡ä»¶", file=sys.stderr)
    print("   - download_dataset_file: ä¸‹è½½æ•°æ®é›†æ–‡ä»¶", file=sys.stderr)
    print("   - get_user_info: è·å–ç”¨æˆ·ä¿¡æ¯", file=sys.stderr)
    print("=" * 50, file=sys.stderr)
    
    # è¿è¡ŒæœåŠ¡å™¨ (STDIO æ¨¡å¼)
    mcp.run(transport='stdio')


if __name__ == "__main__":
    main()
