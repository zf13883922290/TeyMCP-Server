# TeyMCP-Server + NVIDIA GPU å¯¹æ¥ä½¿ç”¨æŒ‡å—

## ğŸ“‹ ç›®å½•

- [ç³»ç»Ÿæ¦‚è¿°](#ç³»ç»Ÿæ¦‚è¿°)
- [å¯¹æ¥æ¶æ„](#å¯¹æ¥æ¶æ„)
- [å¿«é€Ÿå¯¹æ¥](#å¿«é€Ÿå¯¹æ¥)
- [API å¯¹æ¥æ–¹å¼](#api-å¯¹æ¥æ–¹å¼)
- [GPU åŠ é€Ÿé…ç½®](#gpu-åŠ é€Ÿé…ç½®)
- [MCP å·¥å…·ä½¿ç”¨](#mcp-å·¥å…·ä½¿ç”¨)
- [å¸¸è§å¯¹æ¥åœºæ™¯](#å¸¸è§å¯¹æ¥åœºæ™¯)
- [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)

---

## ç³»ç»Ÿæ¦‚è¿°

**TeyMCP-Server** æ˜¯ä¸€ä¸ªæ”¯æŒ GPU åŠ é€Ÿçš„ MCPï¼ˆModel Context Protocolï¼‰å·¥å…·èšåˆæœåŠ¡å™¨ï¼Œæä¾› 125 ä¸ªå·¥å…·å’Œ 17 ä¸ªæœåŠ¡å™¨é›†æˆã€‚

### æ ¸å¿ƒç‰¹æ€§

- âœ… **GPU åŠ é€Ÿæ”¯æŒ**: åŸºäº NVIDIA CUDA 12.3ï¼Œæ”¯æŒå®¹å™¨å†… GPU è®¿é—®
- âœ… **å·¥å…·èšåˆ**: 125 ä¸ªå·¥å…·ç»Ÿä¸€ API è®¿é—®
- âœ… **å®¹å™¨åŒ–éƒ¨ç½²**: Docker + GPU å®Œæ•´æ‰“åŒ…
- âœ… **ç«¯å£éš”ç¦»**: é¿å…å†²çªçš„ç«¯å£æ˜ å°„ç­–ç•¥
- âœ… **å¥åº·ç›‘æ§**: å®æ—¶çŠ¶æ€æ£€æŸ¥å’Œæ—¥å¿—è®°å½•

### ç³»ç»Ÿè¦æ±‚

| ç»„ä»¶ | è¦æ±‚ |
|------|------|
| GPU | NVIDIA GPU (å·²æµ‹è¯•: Tesla P100) |
| é©±åŠ¨ | NVIDIA Driver â‰¥ 450.80.02 |
| CUDA | æ”¯æŒ CUDA 12.3+ |
| Docker | â‰¥ 20.10 |
| NVIDIA Container Toolkit | â‰¥ 1.14.0 |
| ç³»ç»Ÿ | Linux (å·²æµ‹è¯•: Ubuntu 22.04) |

---

## å¯¹æ¥æ¶æ„

### ç½‘ç»œæ‹“æ‰‘

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         å®¿ä¸»æœº (Host)                        â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚       Docker Network: teymcp-network (bridge)         â”‚ â”‚
â”‚  â”‚                   172.28.0.0/16                       â”‚ â”‚
â”‚  â”‚                                                       â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚  TeyMCP-Server       â”‚    â”‚  Ollama (å¯é€‰)    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  GPU Container       â”‚â—„â”€â”€â–ºâ”‚  LLM Container    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚                      â”‚    â”‚                   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  å†…éƒ¨: 8080          â”‚    â”‚  å†…éƒ¨: 11434      â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  å¤–éƒ¨: 1215          â”‚    â”‚  å¤–éƒ¨: 11434      â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  GPU: NVIDIA All     â”‚    â”‚  GPU: NVIDIA All  â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚         â”‚                                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚            â”‚                                              â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚    â”‚   Port 1215     â”‚  â—„â”€â”€â”€ å¤–éƒ¨è®¿é—®å…¥å£                 â”‚
â”‚    â”‚   Port 1216     â”‚  â—„â”€â”€â”€ é¢„ç•™ç«¯å£                    â”‚
â”‚    â”‚   Port 11434    â”‚  â—„â”€â”€â”€ Ollama (å¯é€‰)              â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                                                           â”‚
â”‚    GPU: /dev/nvidia0, /dev/nvidiactl, /dev/nvidia-uvm   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ç«¯å£æ˜ å°„ç­–ç•¥

| å¤–éƒ¨ç«¯å£ | å®¹å™¨ç«¯å£ | æœåŠ¡ | ç”¨é€” |
|---------|---------|------|------|
| 1215 | 8080 | TeyMCP-Server | ä¸» API æœåŠ¡ |
| 1216 | - | é¢„ç•™ | æœªæ¥æ‰©å±• |
| 11434 | 11434 | Ollama | GPU LLM æ¨ç† (å¯é€‰) |

### æ•°æ®å·æ˜ å°„

| å®¿ä¸»æœºè·¯å¾„ | å®¹å™¨è·¯å¾„ | ç±»å‹ | è¯´æ˜ |
|-----------|---------|------|------|
| `./config` | `/app/config` | åªè¯» | é…ç½®æ–‡ä»¶ |
| `teymcp-logs` (volume) | `/app/data/logs` | è¯»å†™ | æ—¥å¿—æŒä¹…åŒ– |
| `teymcp-metrics` (volume) | `/app/data/metrics` | è¯»å†™ | ç›‘æ§æ•°æ® |
| `gpu-cache` (volume) | `/root/.cache` | è¯»å†™ | GPU æ¨¡å‹ç¼“å­˜ |

---

## å¿«é€Ÿå¯¹æ¥

### æ–¹å¼ 1: ä¸€é”®å¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
cd /home/sun/TeyMCP-Server

# æ­¥éª¤ 1: å®‰è£… NVIDIA Container Toolkitï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
sudo bash install_nvidia_container_toolkit.sh

# æ­¥éª¤ 2: å¯åŠ¨ GPU æœåŠ¡
bash start_gpu.sh

# æ­¥éª¤ 3: éªŒè¯æœåŠ¡
curl http://localhost:1215/api/status
```

### æ–¹å¼ 2: Docker Compose æ‰‹åŠ¨å¯åŠ¨

```bash
cd /home/sun/TeyMCP-Server

# æ„å»ºé•œåƒ
docker-compose build

# å¯åŠ¨æœåŠ¡
docker-compose up -d

# éªŒè¯ GPU è®¿é—®
docker exec teymcp-server-gpu nvidia-smi

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:1215/api/status
```

### æ–¹å¼ 3: åŸç”Ÿ Docker è¿è¡Œ

```bash
# æ„å»ºé•œåƒ
docker build -t teymcp-server:gpu-latest .

# è¿è¡Œå®¹å™¨
docker run -d \
  --name teymcp-server-gpu \
  --runtime=nvidia \
  --gpus all \
  -p 1215:8080 \
  -v $(pwd)/config:/app/config:ro \
  -v teymcp-logs:/app/data/logs \
  -e NVIDIA_VISIBLE_DEVICES=all \
  -e NVIDIA_DRIVER_CAPABILITIES=compute,utility \
  --restart unless-stopped \
  teymcp-server:gpu-latest

# éªŒè¯è¿è¡Œ
docker ps | grep teymcp
docker exec teymcp-server-gpu nvidia-smi
```

---

## API å¯¹æ¥æ–¹å¼

### åŸºç¡€ HTTP API

#### 1. å¥åº·æ£€æŸ¥

```bash
curl http://localhost:1215/health
```

å“åº”ç¤ºä¾‹ï¼š
```json
{
  "status": "healthy",
  "timestamp": "2025-11-05T13:15:00Z"
}
```

#### 2. è·å–æœåŠ¡çŠ¶æ€

```bash
curl http://localhost:1215/api/status
```

å“åº”ç¤ºä¾‹ï¼š
```json
{
  "servers": [
    {
      "name": "filesystem",
      "status": "healthy",
      "tools_count": 14
    },
    {
      "name": "github",
      "status": "healthy",
      "tools_count": 13
    }
    // ... å…± 17 ä¸ªæœåŠ¡å™¨
  ]
}
```

#### 3. è·å–å·¥å…·åˆ—è¡¨

```bash
curl http://localhost:1215/api/tools
```

å“åº”ç¤ºä¾‹ï¼š
```json
{
  "tools": [
    {
      "name": "puppeteer_navigate",
      "description": "Navigate to a URL",
      "server": "puppeteer",
      "inputSchema": { ... }
    },
    {
      "name": "mysql_query",
      "description": "Execute SQL query",
      "server": "mysql",
      "inputSchema": { ... }
    }
    // ... å…± 125 ä¸ªå·¥å…·
  ]
}
```

#### 4. è°ƒç”¨ MCP å·¥å…·

```bash
curl -X POST http://localhost:1215/api/tools/call \
  -H "Content-Type: application/json" \
  -d '{
    "tool": "filesystem_read_file",
    "arguments": {
      "path": "/app/README.md"
    }
  }'
```

### Python SDK å¯¹æ¥ç¤ºä¾‹

```python
import requests
import json

class TeyMCPClient:
    def __init__(self, base_url="http://localhost:1215"):
        self.base_url = base_url
    
    def get_status(self):
        """è·å–æœåŠ¡çŠ¶æ€"""
        response = requests.get(f"{self.base_url}/api/status")
        return response.json()
    
    def list_tools(self):
        """åˆ—å‡ºæ‰€æœ‰å·¥å…·"""
        response = requests.get(f"{self.base_url}/api/tools")
        return response.json()
    
    def call_tool(self, tool_name, arguments):
        """è°ƒç”¨å·¥å…·"""
        response = requests.post(
            f"{self.base_url}/api/tools/call",
            json={
                "tool": tool_name,
                "arguments": arguments
            }
        )
        return response.json()

# ä½¿ç”¨ç¤ºä¾‹
client = TeyMCPClient()

# 1. æ£€æŸ¥æœåŠ¡çŠ¶æ€
status = client.get_status()
print(f"æœåŠ¡å™¨æ•°é‡: {len(status['servers'])}")

# 2. åˆ—å‡ºå·¥å…·
tools = client.list_tools()
print(f"å·¥å…·æ•°é‡: {len(tools['tools'])}")

# 3. è°ƒç”¨æ–‡ä»¶ç³»ç»Ÿå·¥å…·
result = client.call_tool(
    "filesystem_list_directory",
    {"path": "/app"}
)
print(f"æ–‡ä»¶åˆ—è¡¨: {result}")

# 4. è°ƒç”¨ GitHub å·¥å…·
result = client.call_tool(
    "github_search_repositories",
    {"query": "MCP server", "limit": 5}
)
print(f"ä»“åº“æœç´¢ç»“æœ: {result}")

# 5. è°ƒç”¨æ•°æ®åº“å·¥å…·
result = client.call_tool(
    "mysql_query",
    {
        "connection_id": "main_db",
        "query": "SELECT * FROM users LIMIT 10"
    }
)
print(f"æŸ¥è¯¢ç»“æœ: {result}")
```

### JavaScript/Node.js å¯¹æ¥ç¤ºä¾‹

```javascript
const axios = require('axios');

class TeyMCPClient {
  constructor(baseURL = 'http://localhost:1215') {
    this.client = axios.create({ baseURL });
  }

  async getStatus() {
    const response = await this.client.get('/api/status');
    return response.data;
  }

  async listTools() {
    const response = await this.client.get('/api/tools');
    return response.data;
  }

  async callTool(toolName, args) {
    const response = await this.client.post('/api/tools/call', {
      tool: toolName,
      arguments: args
    });
    return response.data;
  }
}

// ä½¿ç”¨ç¤ºä¾‹
(async () => {
  const client = new TeyMCPClient();

  // æ£€æŸ¥çŠ¶æ€
  const status = await client.getStatus();
  console.log(`æœåŠ¡å™¨æ•°é‡: ${status.servers.length}`);

  // è°ƒç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–å·¥å…·
  const screenshot = await client.callTool('puppeteer_screenshot', {
    url: 'https://example.com',
    fullPage: true
  });
  console.log('æˆªå›¾ç»“æœ:', screenshot);

  // è°ƒç”¨åª’ä½“ç”Ÿæˆå·¥å…·
  const image = await client.callTool('generate_image_dalle', {
    prompt: 'A beautiful sunset over mountains',
    size: '1024x1024'
  });
  console.log('ç”Ÿæˆçš„å›¾ç‰‡:', image);
})();
```

---

## GPU åŠ é€Ÿé…ç½®

### å¯ç”¨ GPU å·¥å…·

ç¼–è¾‘ `config/servers.yaml` å¯ç”¨ GPU åŠ é€Ÿçš„ MCP æœåŠ¡å™¨ï¼š

```yaml
servers:
  # Ollama æœ¬åœ° LLM (GPU åŠ é€Ÿ)
  ollama:
    enabled: true
    command: "node"
    args: ["/path/to/ollama-mcp-server.js"]
    env:
      OLLAMA_HOST: "http://ollama-gpu:11434"
      CUDA_VISIBLE_DEVICES: "0"
  
  # HuggingFace å®˜æ–¹æœåŠ¡å™¨ (GPU æ¨ç†)
  huggingface_official:
    enabled: true
    command: "uvx"
    args: ["--from", "mcp-server-huggingface", "mcp-server-huggingface"]
    env:
      CUDA_VISIBLE_DEVICES: "0"
      HF_TOKEN: "your_token_here"
  
  # DeepSeek MCP (GPU æ¨ç†)
  deepseek_mcp:
    enabled: true
    command: "uvx"
    args: ["deepseek-mcp"]
    env:
      CUDA_VISIBLE_DEVICES: "0"
      DEEPSEEK_API_KEY: "your_key_here"
```

### GPU å·¥å…·è°ƒç”¨ç¤ºä¾‹

```python
# ä½¿ç”¨ Ollama è¿›è¡Œæœ¬åœ°æ¨ç†
result = client.call_tool(
    "ollama_generate",
    {
        "model": "llama2",
        "prompt": "Explain quantum computing in simple terms",
        "stream": False
    }
)

# ä½¿ç”¨ HuggingFace æ¨¡å‹
result = client.call_tool(
    "huggingface_inference",
    {
        "model": "meta-llama/Llama-2-7b-chat-hf",
        "inputs": "What is the meaning of life?",
        "parameters": {
            "max_length": 200,
            "temperature": 0.7
        }
    }
)

# ä½¿ç”¨åª’ä½“ç”Ÿæˆå·¥å…· (GPU åŠ é€Ÿ)
result = client.call_tool(
    "generate_image_sd",  # Stable Diffusion
    {
        "prompt": "A futuristic city with flying cars",
        "width": 1024,
        "height": 1024,
        "steps": 50
    }
)
```

---

## MCP å·¥å…·ä½¿ç”¨

### å·¥å…·åˆ†ç±» (125 ä¸ªå·¥å…·)

#### ğŸ“‚ æ–‡ä»¶ç³»ç»Ÿå·¥å…· (14 ä¸ª)
- `filesystem_list_directory` - åˆ—å‡ºç›®å½•
- `filesystem_read_file` - è¯»å–æ–‡ä»¶
- `filesystem_write_file` - å†™å…¥æ–‡ä»¶
- `filesystem_create_directory` - åˆ›å»ºç›®å½•
- `filesystem_delete_file` - åˆ é™¤æ–‡ä»¶
- `filesystem_move_file` - ç§»åŠ¨æ–‡ä»¶
- `filesystem_copy_file` - å¤åˆ¶æ–‡ä»¶
- `filesystem_get_file_info` - è·å–æ–‡ä»¶ä¿¡æ¯
- ...ç­‰ 14 ä¸ªå·¥å…·

#### ğŸŒ æµè§ˆå™¨è‡ªåŠ¨åŒ– (15 ä¸ª)
**Puppeteer (14 ä¸ªå·¥å…·):**
- `puppeteer_navigate` - å¯¼èˆªåˆ° URL
- `puppeteer_screenshot` - æˆªå›¾
- `puppeteer_click` - ç‚¹å‡»å…ƒç´ 
- `puppeteer_type` - è¾“å…¥æ–‡æœ¬
- `puppeteer_evaluate` - æ‰§è¡Œ JavaScript
- `puppeteer_select` - é€‰æ‹©ä¸‹æ‹‰æ¡†
- `puppeteer_hover` - æ‚¬åœå…ƒç´ 
- ...ç­‰ 14 ä¸ªå·¥å…·

**Playwright (1 ä¸ªå·¥å…·):**
- `playwright_action` - Playwright è‡ªåŠ¨åŒ–

#### ğŸ™ GitHub é›†æˆ (13 ä¸ª)
- `github_create_repository` - åˆ›å»ºä»“åº“
- `github_search_repositories` - æœç´¢ä»“åº“
- `github_get_file_contents` - è·å–æ–‡ä»¶å†…å®¹
- `github_create_issue` - åˆ›å»ºé—®é¢˜
- `github_create_pull_request` - åˆ›å»º PR
- `github_list_commits` - åˆ—å‡ºæäº¤
- `github_create_branch` - åˆ›å»ºåˆ†æ”¯
- ...ç­‰ 13 ä¸ªå·¥å…·

#### ğŸ—„ï¸ æ•°æ®åº“ç®¡ç† (28 ä¸ª)
**MySQL (11 ä¸ªå·¥å…·):**
- `mysql_connect` - è¿æ¥æ•°æ®åº“
- `mysql_query` - æ‰§è¡ŒæŸ¥è¯¢
- `mysql_execute` - æ‰§è¡Œ SQL
- `mysql_list_databases` - åˆ—å‡ºæ•°æ®åº“
- `mysql_list_tables` - åˆ—å‡ºè¡¨
- `mysql_describe_table` - æè¿°è¡¨ç»“æ„
- `mysql_explain` - åˆ†ææŸ¥è¯¢è®¡åˆ’
- ...ç­‰ 11 ä¸ªå·¥å…·

**SQLite (8 ä¸ªå·¥å…·):**
- `sqlite_query` - æŸ¥è¯¢æ•°æ®
- `sqlite_list_tables` - åˆ—å‡ºè¡¨
- `sqlite_create_record` - åˆ›å»ºè®°å½•
- ...ç­‰ 8 ä¸ªå·¥å…·

**PostgreSQL (9 ä¸ªå·¥å…·):**
- `postgres_query` - æŸ¥è¯¢æ•°æ®
- `postgres_list_schemas` - åˆ—å‡ºæ¨¡å¼
- ...ç­‰ 9 ä¸ªå·¥å…·

#### ğŸ” æœç´¢å¼•æ“ (2 ä¸ª)
- `brave_search` - Brave æœç´¢
- `exa_search` - Exa æœç´¢

#### ğŸ§  çŸ¥è¯†å›¾è°± (9 ä¸ª)
- `memory_create_entities` - åˆ›å»ºå®ä½“
- `memory_add_observations` - æ·»åŠ è§‚å¯Ÿ
- `memory_create_relations` - åˆ›å»ºå…³ç³»
- `memory_read_graph` - è¯»å–å›¾è°±
- ...ç­‰ 9 ä¸ªå·¥å…·

#### ğŸ¨ åª’ä½“ç”Ÿæˆ (8 ä¸ª)
- `generate_image_dalle` - DALL-E å›¾åƒç”Ÿæˆ
- `generate_image_sd` - Stable Diffusion ç”Ÿæˆ
- `edit_image` - ç¼–è¾‘å›¾åƒ
- `convert_image` - è½¬æ¢å›¾åƒæ ¼å¼
- `generate_video` - ç”Ÿæˆè§†é¢‘
- `add_watermark` - æ·»åŠ æ°´å°
- ...ç­‰ 8 ä¸ªå·¥å…·

#### ğŸ¤– æœ¬åœ°è‡ªåŠ¨åŒ– (7 ä¸ª)
- `create_file` - åˆ›å»ºæ–‡ä»¶
- `compress_files` - å‹ç¼©æ–‡ä»¶
- `generate_code` - ç”Ÿæˆä»£ç 
- `batch_rename` - æ‰¹é‡é‡å‘½å
- `create_project` - åˆ›å»ºé¡¹ç›®
- `remote_edit` - è¿œç¨‹ç¼–è¾‘
- ...ç­‰ 7 ä¸ªå·¥å…·

#### â° æ—¶é—´å’Œ Git (6 ä¸ª)
- `time_get_current_time` - è·å–å½“å‰æ—¶é—´
- `time_add_reminder` - æ·»åŠ æé†’
- `git_status` - Git çŠ¶æ€
- `git_commit` - Git æäº¤
- ...ç­‰ 6 ä¸ªå·¥å…·

---

## å¸¸è§å¯¹æ¥åœºæ™¯

### åœºæ™¯ 1: AI åŠ©æ‰‹å¯¹æ¥

**éœ€æ±‚**: è®© AI åŠ©æ‰‹èƒ½è®¿é—®æ–‡ä»¶ã€æµè§ˆç½‘é¡µã€æŸ¥è¯¢æ•°æ®åº“

```python
from teymcp_client import TeyMCPClient

client = TeyMCPClient("http://localhost:1215")

class AIAssistant:
    def __init__(self):
        self.mcp = client
    
    def read_document(self, path):
        """è¯»å–æ–‡æ¡£"""
        return self.mcp.call_tool("filesystem_read_file", {"path": path})
    
    def search_web(self, query):
        """æœç´¢ç½‘é¡µ"""
        return self.mcp.call_tool("brave_search", {"query": query})
    
    def query_database(self, sql):
        """æŸ¥è¯¢æ•°æ®åº“"""
        return self.mcp.call_tool("mysql_query", {
            "connection_id": "main",
            "query": sql
        })
    
    def take_screenshot(self, url):
        """ç½‘é¡µæˆªå›¾"""
        return self.mcp.call_tool("puppeteer_screenshot", {
            "url": url,
            "fullPage": True
        })

# ä½¿ç”¨
assistant = AIAssistant()
content = assistant.read_document("/app/data/report.txt")
results = assistant.search_web("latest AI news")
data = assistant.query_database("SELECT * FROM users LIMIT 10")
screenshot = assistant.take_screenshot("https://example.com")
```

### åœºæ™¯ 2: è‡ªåŠ¨åŒ–æµ‹è¯•å¯¹æ¥

**éœ€æ±‚**: è‡ªåŠ¨åŒ– Web æµ‹è¯•å’Œ API æµ‹è¯•

```python
import time

def automated_test_suite():
    client = TeyMCPClient()
    
    # 1. å¯¼èˆªåˆ°ç™»å½•é¡µé¢
    client.call_tool("puppeteer_navigate", {
        "url": "https://myapp.com/login"
    })
    
    # 2. è¾“å…¥ç”¨æˆ·å
    client.call_tool("puppeteer_type", {
        "selector": "#username",
        "text": "testuser"
    })
    
    # 3. è¾“å…¥å¯†ç 
    client.call_tool("puppeteer_type", {
        "selector": "#password",
        "text": "testpass123"
    })
    
    # 4. ç‚¹å‡»ç™»å½•æŒ‰é’®
    client.call_tool("puppeteer_click", {
        "selector": "#login-button"
    })
    
    time.sleep(2)
    
    # 5. éªŒè¯ç™»å½•æˆåŠŸ
    result = client.call_tool("puppeteer_evaluate", {
        "script": "document.querySelector('.welcome-message').innerText"
    })
    
    assert "Welcome" in result
    
    # 6. æˆªå›¾ä¿å­˜
    client.call_tool("puppeteer_screenshot", {
        "path": "/app/test-results/login-success.png"
    })
    
    print("âœ… æµ‹è¯•é€šè¿‡")

# è¿è¡Œæµ‹è¯•
automated_test_suite()
```

### åœºæ™¯ 3: æ•°æ®åˆ†æå¯¹æ¥

**éœ€æ±‚**: ä»å¤šä¸ªæ•°æ®æºæ”¶é›†æ•°æ®å¹¶åˆ†æ

```python
def data_analysis_pipeline():
    client = TeyMCPClient()
    
    # 1. ä» MySQL è·å–é”€å”®æ•°æ®
    sales_data = client.call_tool("mysql_query", {
        "connection_id": "sales_db",
        "query": """
            SELECT product_id, SUM(amount) as total_sales
            FROM sales
            WHERE date >= '2025-01-01'
            GROUP BY product_id
        """
    })
    
    # 2. ä» SQLite è·å–äº§å“ä¿¡æ¯
    products = client.call_tool("sqlite_query", {
        "database": "products.db",
        "query": "SELECT id, name, category FROM products"
    })
    
    # 3. ä»æ–‡ä»¶ç³»ç»Ÿè¯»å–é…ç½®
    config = client.call_tool("filesystem_read_file", {
        "path": "/app/config/analysis_config.json"
    })
    
    # 4. åˆå¹¶æ•°æ®å¹¶ä¿å­˜ç»“æœ
    # ... æ•°æ®å¤„ç†é€»è¾‘ ...
    
    # 5. å†™å…¥åˆ†ææŠ¥å‘Š
    client.call_tool("filesystem_write_file", {
        "path": "/app/reports/sales_analysis.txt",
        "content": analysis_report
    })
    
    # 6. åˆ›å»º GitHub Issue é€šçŸ¥å›¢é˜Ÿ
    client.call_tool("github_create_issue", {
        "owner": "myorg",
        "repo": "reports",
        "title": "Sales Analysis Report Ready",
        "body": f"New report available at: /app/reports/sales_analysis.txt"
    })
    
    print("âœ… æ•°æ®åˆ†æå®Œæˆ")

# è¿è¡Œåˆ†æ
data_analysis_pipeline()
```

### åœºæ™¯ 4: å†…å®¹ç”Ÿæˆå¯¹æ¥

**éœ€æ±‚**: AI ç”Ÿæˆå†…å®¹å¹¶è‡ªåŠ¨å‘å¸ƒ

```python
def content_generation_workflow():
    client = TeyMCPClient()
    
    # 1. ä½¿ç”¨ Ollama ç”Ÿæˆæ–‡ç« 
    article = client.call_tool("ollama_generate", {
        "model": "llama2",
        "prompt": "Write a blog post about the benefits of containerization",
        "stream": False
    })
    
    # 2. ç”Ÿæˆé…å›¾
    image = client.call_tool("generate_image_dalle", {
        "prompt": "Containerization technology concept art",
        "size": "1024x1024"
    })
    
    # 3. æ·»åŠ æ°´å°
    watermarked = client.call_tool("add_watermark", {
        "image_path": image["path"],
        "text": "Â© MyCompany 2025"
    })
    
    # 4. ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿ
    client.call_tool("filesystem_write_file", {
        "path": "/app/content/blog_post.md",
        "content": article["text"]
    })
    
    # 5. æäº¤åˆ° Git
    client.call_tool("git_commit", {
        "message": "Add new blog post about containerization",
        "files": ["/app/content/blog_post.md"]
    })
    
    # 6. åˆ›å»º Pull Request
    client.call_tool("github_create_pull_request", {
        "owner": "myorg",
        "repo": "blog",
        "title": "New blog post: Containerization",
        "body": "Auto-generated content for review",
        "head": "content/new-post",
        "base": "main"
    })
    
    print("âœ… å†…å®¹ç”Ÿæˆå¹¶æäº¤å®Œæˆ")

# è¿è¡Œå·¥ä½œæµ
content_generation_workflow()
```

---

## æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: GPU æ— æ³•è®¿é—®

**ç—‡çŠ¶**: å®¹å™¨å†… `nvidia-smi` å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ GPU é©±åŠ¨
nvidia-smi

# æ£€æŸ¥ NVIDIA Container Toolkit
nvidia-ctk --version

# é‡æ–°é…ç½® Docker Runtime
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker

# éªŒè¯ GPU è®¿é—®
docker run --rm --runtime=nvidia --gpus all nvidia/cuda:12.3.0-base-ubuntu22.04 nvidia-smi
```

### é—®é¢˜ 2: ç«¯å£å†²çª

**ç—‡çŠ¶**: `docker-compose up` æŠ¥ç«¯å£å·²è¢«å ç”¨

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ç«¯å£å ç”¨
sudo netstat -tlnp | grep 1215

# åœæ­¢å ç”¨ç«¯å£çš„è¿›ç¨‹
sudo kill <PID>

# æˆ–ä¿®æ”¹ docker-compose.yml ç«¯å£æ˜ å°„
ports:
  - "æ–°ç«¯å£:8080"  # æ”¹ä¸ºæœªå ç”¨çš„ç«¯å£
```

### é—®é¢˜ 3: MCP å·¥å…·è°ƒç”¨å¤±è´¥

**ç—‡çŠ¶**: API è¿”å› 500 é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker logs teymcp-server-gpu --tail 100

# æ£€æŸ¥ MCP æœåŠ¡çŠ¶æ€
curl http://localhost:1215/api/status

# é‡å¯æœåŠ¡
docker-compose restart

# æ£€æŸ¥é…ç½®æ–‡ä»¶
cat config/servers.yaml
```

### é—®é¢˜ 4: å†…å­˜ä¸è¶³

**ç—‡çŠ¶**: å®¹å™¨ OOM (Out of Memory)

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ GPU å†…å­˜ä½¿ç”¨
nvidia-smi

# å¢åŠ å®¹å™¨å†…å­˜é™åˆ¶ (ç¼–è¾‘ docker-compose.yml)
services:
  teymcp:
    deploy:
      resources:
        limits:
          memory: 16G  # å¢åŠ å†…å­˜é™åˆ¶
```

### é—®é¢˜ 5: æœåŠ¡å¯åŠ¨æ…¢

**ç—‡çŠ¶**: `docker-compose up` é•¿æ—¶é—´æ— å“åº”

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å¢åŠ  healthcheck å¯åŠ¨æ—¶é—´
healthcheck:
  start_period: 120s  # å¢åŠ åˆ° 120 ç§’

# æŸ¥çœ‹å¯åŠ¨æ—¥å¿—
docker-compose logs -f teymcp

# æ£€æŸ¥ GPU åˆå§‹åŒ–
docker exec teymcp-server-gpu nvidia-smi
```

---

## ç›‘æ§å’Œç»´æŠ¤

### å®æ—¶ç›‘æ§

```bash
# ä½¿ç”¨ç›‘æ§è„šæœ¬ï¼ˆæ¨èï¼‰
bash monitor_gpu.sh

# æ‰‹åŠ¨ç›‘æ§ GPU
watch -n 1 nvidia-smi

# ç›‘æ§å®¹å™¨èµ„æº
docker stats teymcp-server-gpu

# æŸ¥çœ‹ MCP æœåŠ¡çŠ¶æ€
watch -n 5 'curl -s http://localhost:1215/api/status | jq'
```

### æ—¥å¿—ç®¡ç†

```bash
# æŸ¥çœ‹å®æ—¶æ—¥å¿—
docker logs -f teymcp-server-gpu

# æŸ¥çœ‹æœ€è¿‘ 100 è¡Œæ—¥å¿—
docker logs teymcp-server-gpu --tail 100

# å¯¼å‡ºæ—¥å¿—
docker logs teymcp-server-gpu > teymcp.log

# æ¸…ç†æ—§æ—¥å¿—
docker-compose down
docker volume rm teymcp-logs
```

### å¤‡ä»½å’Œæ¢å¤

```bash
# å¤‡ä»½é…ç½®
tar -czf teymcp-backup-$(date +%Y%m%d).tar.gz config/

# å¤‡ä»½æ•°æ®å·
docker run --rm -v teymcp-logs:/data -v $(pwd):/backup \
  ubuntu tar -czf /backup/logs-backup.tar.gz /data

# æ¢å¤é…ç½®
tar -xzf teymcp-backup-20251105.tar.gz

# æ¢å¤æ•°æ®å·
docker run --rm -v teymcp-logs:/data -v $(pwd):/backup \
  ubuntu tar -xzf /backup/logs-backup.tar.gz -C /
```

---

## æ€§èƒ½ä¼˜åŒ–

### GPU ä¼˜åŒ–

```yaml
# docker-compose.yml
services:
  teymcp:
    environment:
      # ä¼˜åŒ– CUDA è®¾ç½®
      - CUDA_VISIBLE_DEVICES=0  # ä½¿ç”¨ç‰¹å®š GPU
      - CUDA_LAUNCH_BLOCKING=1  # è°ƒè¯•æ¨¡å¼
      - CUDA_CACHE_PATH=/root/.cache/cuda
    
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1  # é™åˆ¶ GPU æ•°é‡
              capabilities: [gpu, compute]  # æœ€å°æƒé™
```

### å†…å­˜ä¼˜åŒ–

```yaml
services:
  teymcp:
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G
```

### å¹¶å‘ä¼˜åŒ–

```bash
# å¢åŠ  worker æ•°é‡ï¼ˆç¼–è¾‘ src/main.pyï¼‰
uvicorn.run(
    "main:app",
    host="0.0.0.0",
    port=8080,
    workers=4  # å¢åŠ  worker æ•°é‡
)
```

---

## å®‰å…¨å»ºè®®

1. **API è®¿é—®æ§åˆ¶**: é…ç½® API å¯†é’¥è®¤è¯
2. **ç½‘ç»œéš”ç¦»**: ä½¿ç”¨ Docker ç½‘ç»œéš”ç¦»
3. **æƒé™æœ€å°åŒ–**: å®¹å™¨ä»¥é root ç”¨æˆ·è¿è¡Œ
4. **æ—¥å¿—å®¡è®¡**: å®šæœŸæ£€æŸ¥è®¿é—®æ—¥å¿—
5. **å®šæœŸæ›´æ–°**: ä¿æŒ NVIDIA é©±åŠ¨å’Œå·¥å…·é“¾æœ€æ–°

---

## æŠ€æœ¯æ”¯æŒ

- **æ–‡æ¡£**: `docs/GPU_SETUP.md` - å®Œæ•´é…ç½®æŒ‡å—
- **å¿«é€Ÿå¼€å§‹**: `GPU_QUICKSTART.md` - 5 åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹
- **æµ‹è¯•æŠ¥å‘Š**: `GPU_TEST_REPORT.md` - æµ‹è¯•ç»“æœå’ŒéªŒè¯
- **è„šæœ¬å·¥å…·**: 
  - `start_gpu.sh` - å¯åŠ¨è„šæœ¬
  - `test_gpu.sh` - æµ‹è¯•è„šæœ¬
  - `monitor_gpu.sh` - ç›‘æ§è„šæœ¬

---

## æ›´æ–°æ—¥å¿—

### v1.0.0 (2025-11-05)

- âœ… å®Œæˆ NVIDIA Container Toolkit é›†æˆ
- âœ… å®ç° GPU å®¹å™¨åŒ–éƒ¨ç½²
- âœ… é…ç½®ç«¯å£æ˜ å°„ç­–ç•¥ (1215, 1216, 11434)
- âœ… é›†æˆ 125 ä¸ª MCP å·¥å…·
- âœ… åˆ›å»ºå®Œæ•´æ–‡æ¡£ä½“ç³»
- âœ… å®ç°ç›‘æ§å’Œç®¡ç†è„šæœ¬
- âœ… é€šè¿‡å…¨éƒ¨ 8 é¡¹æµ‹è¯•
- âœ… æ”¯æŒ Ollama æœ¬åœ° LLM (å¯é€‰)

---

**ç‰ˆæœ¬**: v1.0.0  
**æµ‹è¯•çŠ¶æ€**: âœ… 100% é€šè¿‡  
**GPU æ”¯æŒ**: âœ… Tesla P100 éªŒè¯  
**å·¥å…·æ•°é‡**: 125 ä¸ª  
**æœåŠ¡å™¨æ•°é‡**: 17 ä¸ª  
**å°±ç»ªçŠ¶æ€**: ğŸš€ ç”Ÿäº§å°±ç»ª
